# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t5F3Erq_6IhzF2FSa2kIXKV037_mZzTt
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv('/content/LokSabha&RajyaSabhaCriminalRecord_Final.csv')


df.head()

print(df.dtypes)

total_serious_cases = df['serious_cases'].sum()
average_serious_cases = df['serious_cases'].mean()
print("Total Serious Cases:", total_serious_cases)
print("Average Serious Cases:", average_serious_cases)

# Visualize the distribution
import matplotlib.pyplot as plt

df['serious_cases'].hist()
plt.xlabel('Number of Serious Cases')
plt.ylabel('Frequency')
plt.title('Distribution of Serious Cases')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# Feature selection
features = ['age', 'assets', 'liabilities', 'income', 'gender_encoded', 'education_encoded']
X = df[features]
y = df['serious_cases']  # Target variable

X.fillna(0, inplace=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a model (e.g., Random Forest Classifier)
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Compute performance metrics
# Compute performance metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass
recall = recall_score(y_test, y_pred, average='weighted')        # Use 'weighted' for multiclass
f1 = f1_score(y_test, y_pred, average='weighted')


print(f"Accuracy: {accuracy:.2f}")
print(f"Precision (weighted): {precision:.2f}")
print(f"Recall (weighted): {recall:.2f}")
print(f"F1 Score (weighted): {f1:.2f}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset (assuming it's a CSV file)
data = pd.read_csv("/content/LokSabha&RajyaSabhaCriminalRecord_Final.csv")

# Select features and target
features = ['assets', 'liabilities', 'cases']
target = 'serious_cases'

X = data[features]
y = data[target]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Function to predict serious cases for a given candidate
def predict_serious_cases(candidate_name):
    candidate_data = data[data['name'] == candidate_name][features]
    if candidate_data.empty:
        return f"Candidate {candidate_name} not found."
    else:
        prediction = model.predict(candidate_data)
        predicted_cases = int(prediction[0])

        # Visualize candidate data based on the predicted serious cases
        if predicted_cases > 8:
            visualize_candidate_data(candidate_name, candidate_data, 'above')
        else:
            visualize_candidate_data(candidate_name, candidate_data, 'below')

        return f"Predicted number of serious cases for {candidate_name}: {predicted_cases}"

# Function to visualize candidate data
def visualize_candidate_data(candidate_name, candidate_data, threshold_status):
    plt.figure(figsize=(10, 6))
    sns.barplot(x=candidate_data.columns, y=candidate_data.iloc[0])
    plt.title(f"Feature Values for {candidate_name} (Threshold: {threshold_status} 8)")
    plt.ylabel('Values')
    plt.xlabel('Features')
    plt.show()

# Example usage
candidate_name = input('Enter the candidate name: ')
print(predict_serious_cases(candidate_name))

